{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eroY5nKeB5s_"
   },
   "source": [
    "## IMPORTING THE LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rpot3-uYB4Tc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dblkODQhCIAD"
   },
   "source": [
    "## IMPORTING AND ANALYSIS THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vio32CeuCTKn",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainData = pd.read_csv('Training.csv')\n",
    "testData = pd.read_csv('Testing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ey6PEecwPBCG"
   },
   "outputs": [],
   "source": [
    "trainData = trainData.iloc[:, :-1]\n",
    "train_names = list(trainData.columns)\n",
    "print(train_names.pop())\n",
    "print(trainData.info())\n",
    "print(testData.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gqu5IkMwPCz7"
   },
   "outputs": [],
   "source": [
    "print(trainData.shape)\n",
    "print(testData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F6hHeEGSPEka"
   },
   "outputs": [],
   "source": [
    "trainData.isnull().sum()  #early info of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "group_counts = Counter(trainData['prognosis'])\n",
    "for item in group_counts:\n",
    "    print(item ,\": \", group_counts[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "trainData['prognosis'] = le.fit_transform(trainData['prognosis'])\n",
    "testData['prognosis'] = le.transform(testData['prognosis'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RVggWdnpEy0S"
   },
   "source": [
    "## SPLITTING TRAINING SET AND TEST SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0dMxnvEPQwQo"
   },
   "outputs": [],
   "source": [
    "X_train = trainData.drop(['prognosis'], axis=1)\n",
    "y_train = trainData['prognosis']\n",
    "X_test = testData.drop(['prognosis'], axis=1)\n",
    "y_test = testData['prognosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lALGCrUxRf-w"
   },
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hd2pZioiFtoy"
   },
   "source": [
    "# TRAINING MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZB4bGQVra2gd"
   },
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DPaBPZFOaxCN"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UEBiphd3a73Y"
   },
   "source": [
    "### KNN Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_79XyCCHan_3"
   },
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "# classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RkwfyOtfbAm4"
   },
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AzPJL5NcalK0"
   },
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "# classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "# classifier.fit(X_train, y_train, feature_names = train_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kFmZSDWQbDJI"
   },
   "source": [
    "### Kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Rm54Nl7F29Y"
   },
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "# classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "# classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wEzWCqNqbiKe"
   },
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uXy5GZQFbk1I"
   },
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# classifier = GaussianNB()\n",
    "# classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgYf8V0ycIkc"
   },
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lp69XWPwcMq2"
   },
   "outputs": [],
   "source": [
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "# classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4g1OskTOco5c"
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oxx1xjIccsah"
   },
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "# classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8OF6_84GdWiq"
   },
   "source": [
    "### XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "21mawDlbdYq3"
   },
   "outputs": [],
   "source": [
    "# from xgboost import XGBClassifier\n",
    "# classifier = XGBClassifier()\n",
    "# classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JOaHKyWbGBYQ"
   },
   "source": [
    "## PREDICTING TEST SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xKjEoWpeGU_Y"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "for i in range(len(y_pred)):\n",
    "    print(y_pred[i], \":  \", y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6BWUVa4XGcVh"
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the classifier \n",
    "# printing every score of the classifier \n",
    "# scoring in anything \n",
    "from sklearn.metrics import classification_report, accuracy_score \n",
    "from sklearn.metrics import precision_score, recall_score \n",
    "from sklearn.metrics import f1_score, matthews_corrcoef \n",
    "from sklearn.metrics import confusion_matrix \n",
    " \n",
    "n_errors = (y_pred != y_test).sum() \n",
    "print(f\"No of incorrect: {n_errors}\")\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred) \n",
    "print(\"The accuracy is {}\".format(acc)) \n",
    "\n",
    "prec = precision_score(y_test, y_pred, average='micro') \n",
    "print(\"The precision is {}\".format(prec))  #predicted fraud was actually fraud\n",
    "\n",
    "rec = recall_score(y_test, y_pred, average='micro')         #actual fraud was predicted fraud\n",
    "print(\"The recall is {}\".format(rec)) \n",
    "\n",
    "f1 = f1_score(y_test, y_pred, average='micro') \n",
    "print(\"The F1-Score is {}\".format(f1)) \n",
    "\n",
    "MCC = matthews_corrcoef(y_test, y_pred) \n",
    "print(\"The Matthews correlation coefficient is {}\".format(MCC)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = [item for item in group_counts]\n",
    "conf_matrix = confusion_matrix(y_test, y_pred) \n",
    "plt.figure(figsize =(10, 10)) \n",
    "sb.heatmap(conf_matrix, xticklabels = LABELS,  \n",
    "            yticklabels = LABELS, annot = True, fmt =\"d\"); \n",
    "plt.title(\"Confusion matrix\") \n",
    "plt.ylabel('True class') \n",
    "plt.xlabel('Predicted class') \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U-eGh0nuyabx"
   },
   "source": [
    "## Applying k-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P1gUQkreWJ1J"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 3)\n",
    "print(\"Max accuracy: {:.5f} %\".format(max(accuracies)*100))\n",
    "print(\"Min accuracy: {:.5f} %\".format(min(accuracies)*100))\n",
    "print(\"Accuracy: {:.5f} %\".format(accuracies.mean()*100))\n",
    "print(\"Standard Deviation: {:.5f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OfdKjXJNGsHC"
   },
   "source": [
    "## PREDICTING SINGLE VALUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dqhEW6g7UdE5"
   },
   "outputs": [],
   "source": [
    "print()\n",
    "l1 = [\"lack_of_concentration\", \"watering_from_eyes\"]\n",
    "l2 = []\n",
    "l = []\n",
    "i = 0\n",
    "j = 0\n",
    "for i in range(len(train_names)):\n",
    "    if j == len(l1):\n",
    "        l2.append(0)\n",
    "    elif l1[j] == train_names[i]:\n",
    "        l2.append(1)\n",
    "        j += 1\n",
    "    else:\n",
    "        l2.append(0)\n",
    "    i += 1\n",
    "l.append(l2)\n",
    "print(\"Symtops: \", l1)\n",
    "print(\"Predicted Disease: \")\n",
    "print(le.inverse_transform((classifier.predict(l))))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
